# Part 2

| Function | Optimal runtime |
|---|---|
| insert() | O(n) |
| size() | O(1) |
| empty() | O(1) |
| erase() | O(n) |
| copy constr. | O(n) | 
| copy assignment  | O(n) |
| move constr. | O(1) |
| move assignment | O(1) |

# Part 5

Place the analysis of the majority element and find candidate function

Find Candidate Function

```cpp
bool findCandidate(int array[],int& candidate, int sz){
    if (sz == 0) {
        if (candidate < 0 || candidate > 1000000) {
            return false;
        }
        return true;
    }
    else if (sz == 1) {
        candidate = array[0];
        return true;
    }
    int size = 0;
    if (sz % 2 == 0) {
        for (int i = 0; i < sz; i+=2) {
            if (array[i] == array[i + 1]) {
                array[size] = array[i];
                size++; n/2
            }
         }
    }
    else {
        for (int i = 0; i < sz - 1; i+=2) {
            if (array[i] == array[i + 1]) {
                array[size] = array[i];
                size++;
            }
        }
        candidate = array[sz - 1];
    }
    return findCandidate(array, candidate, size);
}
```
Let $n$ represent the size of the array.<br />
Let $T(n)$ represent number of operations needed to find the candidate.

This function calls itself $O(logn)$ times due to the size getting cut everytime.<br />
Each recursive call will run at least one linear for loop to find matching pairs. $O(nlogn)$<br />
Any constant time operations are ignored because "dominated" by the higher-order complexities.

Therefore, the time complexity is:
$T(n) = O(nlogn)$

```cpp
bool majorityElement(const int arr[], int& majority, int sz){
    int count = 0;
    int newArr[sz];
    for (int i = 0; i < sz; i++) {
        newArr[i] = arr[i];
    }
    bool next = findCandidate(newArr, majority, sz);
    for (int i = 0; i < sz && next == true; i++) {
        if (arr[i] == majority) {
            count++;
        }
    }
 
 
    if (count > sz / 2) {
        return true;
    }
 
    else {
        return false;
    }
        
}
```

Let $n$ represent the size of the array.<br />
Let $T(n)$ represent number of operations needed to check the majority element.

The first loop to copy the array will be $O(n)$.<br />
The call to the recursive function will be $O(nlogn)$ as calculated above.<br />
The second loop to check if the majority is the candidate is $O(n)$.<br />
Any constant time operations are ignored because "dominated" by the higher-order complexities.<br />
$O(nlogn)$ is the most dominant time complexity.<br />

Therefore, the time complexity is:
$T(n) = O(nlogn)$


# Part 6 (team member: Jacky Yuanqing Dai)
I learned that Linked List operations are very pointer intensive. The search function, insert function and copy assignment/constructor often break and re-weave the pointers in the linked list. It really helped me improve my understanding of pointers. I also learned how important visualization is in programming and designing an algorithm. Me and my partner drew on the whiteboard to draw the state of a linked list and use that drawing to think through the code. The find candidate function was very challeninging to code. Recursion in general feels like it requires mental leaps and thinking ahead while iterative algorithms can allow me to code in small incremental steps. It feels harder to think in the lines of program excution but it does make the code cleaner (less lines of code). It really helped adding multiple debug lines of code to see where the program was going with each iteration.

# Part 6 (team member: Armen Merzaian)
During this Assignment I learned how complex the internal structure of a LinkedList and it's operations truly are. Linked Lists have 4 major parts: The data Nodes, the sentinels, the iterators, and the List itself. All of these functions require persise handling of pointers to achieve a scalable List that is easy to use for the end user. A lot of what I learned was handling simple algorithms such as sorting and moving nodes in order to implement features such as the Cache. The biggest challenge I faced when developing the algorithms what visualizing where the pointers were pointing and what the next step was going to look like. Working with a parner was very helpful as we were able to bounce ideas off eachother explain concepts to eachother when one of us was getting lost. Another big challenege I faced was developing the recursive function findCandidate(). This was a major challenge because there were many edge cases that we needed to account for which is difficult in a recursive function when you cannot save state. 

